{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7fadf88-3f5d-4711-9ae6-7eae17b61a57",
   "metadata": {},
   "source": [
    "# Web Scraping IWF Website For Phuket 2024 Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085ec12-5a6b-439d-a7a2-e12292f8d26d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries required for task\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bedd18-3358-4150-8b69-dc12ddd3837b",
   "metadata": {},
   "source": [
    "## Resources Used\n",
    "- 2024.09.12/ChatGPT accessed\n",
    "- 2024.09.11/[Repository](https://github.com/jwc20/iwf_api/blob/main/iwf/result.py) accessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d8d8a-6dc4-4125-9381-d17092756312",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [IWF Web Scraping](#IWF-Web-Scraping)\n",
    "- [Clean & Feature Engineer Scraped Data](#Clean-&-Feature-Engineer-Scraped-Data)\n",
    "- [Merge With Provided_Data](#Merge-With-Provided-Data)\n",
    "- [Verify Merge and Write To CSV](#Verify-Merge-and_Write-To-CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd5fcf-1f26-45af-b8af-5e334e1d605f",
   "metadata": {},
   "source": [
    "## IWF Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73c5e5-aad0-4ae8-b720-f72be4ccb6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the URL and get a response\n",
    "url = 'https://iwf.sport/results/results-by-events/?event_id=599'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74edb8-f41a-422c-9706-fa5097b12dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Success!\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1690a-ed64-47b9-b336-08514cd838c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the response into html text, then parse with BeautifulSoup\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaad9df4-4a15-4a2d-8b44-4f327c1c6824",
   "metadata": {},
   "source": [
    "#### I only need data from the Men and Women's Snatch & Clean and Jerk.  The HTML is structured to have a 'result__container' and each are labeled with one of the four different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0228569-d572-4fb2-99e4-6ff7fb92b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all of the result__container div classes and verify that each one has their own category.\n",
    "result_containers = soup.find_all('div', {'class':'result__container'})\n",
    "\n",
    "for id in result_containers:\n",
    "    print(id.get('id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e94a6-6f5d-44a5-a84c-ef9ef3ed1365",
   "metadata": {},
   "source": [
    "#### The following section will pull requested project data from the 2024 IWF World Cup Paris Qualifying Event in Phuket and consolidate data into one dataframe.\n",
    "- Looks for result_containers that have either the 'men_snatchjerk' or 'women_snatchjerk' ID.\n",
    "- Pulls all of the div tags with the 'cards' class and put them into a 'cards_group' variable.\n",
    "- Looks for all div classes with the 'card' class within the 'cards_group' variable and puts them into a 'card_box' variable.\n",
    "- Runs three 'for' loops to collect snatch, clean and jerk, and total lift data.\n",
    "- Collects all of the data into three separate dataframes for snatch, clean and jerk, and total lift data, then merges on competitor name into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa05d00-efcb-4e1d-b5b5-8c1c63c2dddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create empty lists for each requested lift category so they can later be transformed into dataframes\n",
    "snatch_list = []\n",
    "cj_list = []\n",
    "total_list = []\n",
    "\n",
    "# For loop check if the div ID of the result__container and if satisfies the criteria, it finds all of the divs with the 'cards' class and \n",
    "# put it into a cards_group varaible.\n",
    "\n",
    "for category in result_containers:\n",
    "    if category.get('id') == 'men_snatchjerk' or category.get('id') == 'women_snatchjerk':\n",
    "        cards_group = category.find_all('div', {'class':'cards'})\n",
    "        \n",
    "# SNATCH DATA SCRAPE\n",
    "# Following pair of for loops iteratres through the cards_group associated with snatch data (every third group starting with first group) and puts\n",
    "# it into a 'card_box' variable.  For every card in the box, except the first one because it just contains column labels, second loop will check for\n",
    "# specific 'p' tags that hold requested data to scrape.  Pulling name for each category of lifts so that they can later be merged. Creates key\n",
    "# value pairs for data points and appends them to list.\n",
    "        \n",
    "        for cards in cards_group[::3]:\n",
    "            card_box = cards.find_all('div', {'class':'card'})\n",
    "\n",
    "            for card in card_box[1:]:\n",
    "                snatch_data = {}\n",
    "                snatch_data['name'] = card.find_all('p')[1].text.strip()\n",
    "                snatch_data['country'] = card.find_all('p')[2].text.strip()\n",
    "                snatch_data['snatch1'] = card.find_all('p')[6].strong.contents[0]\n",
    "                snatch_data['snatch2'] = card.find_all('p')[7].strong.contents[0]\n",
    "                snatch_data['snatch3'] = card.find_all('p')[8].strong.contents[0]\n",
    "                snatch_list.append(snatch_data)\n",
    "\n",
    "# CLEAN AND JERK DATA SCRAPE\n",
    "# Does the same as the snatch data scrape except that it looks through each clean and jerk weight category (every third group starting with\n",
    "# the second group.\n",
    "        \n",
    "        for cards in cards_group[1::3]:\n",
    "            card_box = cards.find_all('div', {'class':'card'})\n",
    "\n",
    "            for card in card_box[1:]:\n",
    "                cj_data = {}\n",
    "                cj_data['name'] = card.find_all('p')[1].text.strip()\n",
    "                cj_data['cj1'] = card.find_all('p')[6].strong.contents[0]\n",
    "                cj_data['cj2'] = card.find_all('p')[7].strong.contents[0]\n",
    "                cj_data['cj3'] = card.find_all('p')[8].strong.contents[0]\n",
    "                cj_list.append(cj_data)\n",
    "\n",
    "# SUM LIFT DATA SCRAPE\n",
    "# Does the same as the snatch and clean and jerk data scrapes.  Sum lift is the combined sum of an athlete's best snatch and clean and jerk\n",
    "# successful lifts.  \n",
    "\n",
    "        for cards in cards_group[2::3]:\n",
    "            card_box = cards.find_all('div', {'class':'card'})\n",
    "\n",
    "            for card in card_box[1:]:\n",
    "                sum_data = {}\n",
    "                sum_data['name'] = card.find_all('p')[1].text.strip()\n",
    "                sum_data['total'] = card.find_all('p')[8].strong.contents[1]\n",
    "                total_list.append(sum_data)\n",
    "\n",
    "# Transforms list data for each lift category into dataframes\n",
    "\n",
    "snatch_df = pd.DataFrame(snatch_list)\n",
    "cj_df = pd.DataFrame(cj_list)\n",
    "total_df = pd.DataFrame(total_list)\n",
    "\n",
    "# Combines all three dataframes into one, merging on the 'name' column using the reduce function\n",
    "\n",
    "dfs = [snatch_df, cj_df, total_df]\n",
    "iwf_df = reduce(lambda left, right: pd.merge(left, right, on = 'name'), dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e5eec-692a-4710-ad45-379b0dd96551",
   "metadata": {},
   "source": [
    "## Clean & Feature Engineer Scraped Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5fadd-5276-414e-ae27-8022275aba0d",
   "metadata": {},
   "source": [
    "#### Requested data has been scraped, but needs a bit more clean-up and feature engineering: Add columns to indicate if a lift was success or not as well as edit lift columns so they can be integers for potential calculations in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff59e5-5a54-416e-96cb-27685beca155",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iwf_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af2415-eb66-4bc1-a6d1-af5a9328fee9",
   "metadata": {},
   "source": [
    "#### The values are either a NavigableString or a Tag since the values were parsed through BeautifulSoup.  First a function will be created to check if an athlete was successful with a lift and create Boolean colums to reflect results. Another function will transform the weight data into integers and turn any '---' values into 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebde8b6-7cf6-4c1a-bda9-199e9275c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_success_check(weight):\n",
    "    '''\n",
    "    Accepts a weight value from one of the snatch or clean and jerk categories. Checks if a lift weight is a NavigableString and does not\n",
    "    equal '---'.  If statements are satisfied, the function returns True.  Otherwise it returns False.  This is meant to check if the\n",
    "    athlete successfully lifted the weight.  If it's in brackets (a Tag) or is '---', that means the athelete was either not able\n",
    "    to lift weight or didn't participate.\n",
    "    '''\n",
    "    return type(weight) == NavigableString and weight != '---'\n",
    "\n",
    "def int_transformer(weight):\n",
    "    '''\n",
    "    Accepts a weight value from one of the snatch or clean and jerk categories.  Checks if the value does not equal '---'.  If it does not, the\n",
    "    function will change the value into an integer.  Otherwise it replaces '---' with 0.  This is to antipicate any need for calculations with\n",
    "    the lift weight values.\n",
    "    '''\n",
    "    \n",
    "    if weight != '---':\n",
    "        return int(weight.text)\n",
    "    else:\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f84cd8-298c-4cbf-bcc2-ad543722ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns lists so that functions can be applied to them.  Separate list for the int_transformer column\n",
    "# since there is no success or fail metric or total lift, but it needs to be transformed into an integer.\n",
    "lift_columns = ['snatch1', 'snatch2', 'snatch3', 'cj1', 'cj2', 'cj3']\n",
    "lift_and_total_columns = ['snatch1', 'snatch2', 'snatch3', 'cj1', 'cj2', 'cj3', 'total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184224b-91d5-4fb9-aa94-46d98374a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above functions applied to dataframe\n",
    "for column in lift_columns:\n",
    "    iwf_df[f'{column}_success'] = iwf_df[column].apply(lift_success_check)\n",
    "\n",
    "for column in lift_and_total_columns:\n",
    "    iwf_df[column] = iwf_df[column].apply(int_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7137729-8460-4ef4-b4d2-9cc28ed8c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iwf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a1c06-078f-4fd0-a64c-0218972c7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "iwf_df.to_csv('../data/phuket_2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6ac29-26d1-4676-82c7-19c1750aa52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iwf_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58295f-4ad1-472a-b718-f1fc33df13df",
   "metadata": {},
   "source": [
    "## Merge With Provided Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d78c87-3b71-4521-9198-397ce71f8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightlift_df = pd.read_excel('../data/weightlifting_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf072d0-d38b-4d80-9b08-33e350b0cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noticed the 'PersonID' was sometimes reading as dates in Excel, so changed the column from 'general' to 'number' with no decimals.\n",
    "weightlift_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db98aa-37b3-4936-a1c9-dacfdfd0e36d",
   "metadata": {},
   "source": [
    "#### Transforming names to snake case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93242bfa-4b43-4275-9ede-ca0b19180078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not strictly necessary, but I prefer snake case.\n",
    "def snake_case(title):\n",
    "    pattern = re.compile(r'(?<!^)(?=[A-Z])')\n",
    "    return pattern.sub('_', title).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68fe61-691d-4039-a3be-c32d0012eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightlift_df.columns = [snake_case(column) for column in weightlift_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e9933-1325-4ae3-a2d2-b03298ddf998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not perfect - EventID turned into event_i_d, but will keep\n",
    "weightlift_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e1f9a-a633-4c59-9ad2-1e0dd0ef66c1",
   "metadata": {},
   "source": [
    "#### I found discrepancies in competitor name structures between the website data and the provided Excel sheet.  \n",
    "\n",
    "#### Initially, Fuzzy Wuzzy was used for name matching; however, some matches were found to be incorrect. To improve accuracy, competitor country data was scraped from the IWF website and used as a confirmation alongside fuzzy matching. The function below calculates a 'best_score' for each name comparison and checks if the country codes match.  \n",
    "\n",
    "#### If the country codes match, a bonus is added to name_score. The function selects the highest-scored name from the IWF DataFame to match with the weightlifting dataFrame. Finally, the datasets are merged based on the best matching name, and the resulting dataset is cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faded78-b8f8-4ae0-8fcf-e8087639c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "iwf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4b7fa-23a6-4298-8e36-532ebd7d3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightlift_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b72ce9e-ad84-44a6-8f5e-a59cd13bf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_name_merge(df_1, df_2, name_col1, name_col2, country_col1, country_col2):\n",
    "    '''\n",
    "    df1 = First dataframe to merge\n",
    "    df2  = Second dataframe to merge\n",
    "    name_col1 = Column of names from df1\n",
    "    name_col2 - Column of names for df2\n",
    "    country_col1 = Column of countries from df1\n",
    "    country_col2 = Column of countries from df2\n",
    "\n",
    "    Function makes a copy of df1 and execute 'find_best_match' function.\n",
    "    It will then unzip tuple return data from 'find_best_match' function and assign them to 'best_match' and 'match_score' columns.\n",
    "    Function will merge 'merged_df'(copy of df1) with df2 on the best_match column.\n",
    "    Several columns are dropped and renamed as needed. Columns are reorganized before being returned.\n",
    "    '''\n",
    "    # Create a copy of df_1(weightlift_df)\n",
    "    merged_df = df_1.copy()\n",
    "\n",
    "    # Function finds the best match based on fuzzy matching combined with competitor country matches\n",
    "    def find_best_match(row, candidates):\n",
    "        '''\n",
    "        row = Row from 'merged_df'(copy of df1 from fuzzy_name_merge function)\n",
    "        candidates = df2 from fuzzy_name_merge function\n",
    "\n",
    "        Function will first compare the country from df1 with country from df2 row by row.  It will then use fuzzy's token set ratio\n",
    "        to compare the current row's name in df1 with names in df2 and assign a score.  If the countries also match, the function\n",
    "        will assign a bonus.  This will happen for each row in df1 and the top score and name associated with the score is tracked.\n",
    "        The name with the highest score along with its score is return as a tuple.\n",
    "        '''\n",
    "        name = row[name_col1]\n",
    "        country = row[country_col1]\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        for index, candidate in candidates.iterrows():\n",
    "            # Check if countries match\n",
    "            country_match = (country == candidate[country_col2])\n",
    "            \n",
    "            # Compare and score names from weightlifting and iwf datasets based on similiarity\n",
    "            name_score = fuzz.token_set_ratio(name.lower(), candidate[name_col2].lower())\n",
    "            \n",
    "            # Boost score if countries match\n",
    "            adjusted_score = name_score + 20 if country_match else name_score\n",
    "\n",
    "            # Check if current calculated score is the best one so far and update 'best_score' and associated name with that score\n",
    "            if adjusted_score > best_score:\n",
    "                best_score = adjusted_score\n",
    "                best_match = candidate[name_col2]\n",
    "        \n",
    "        return best_match, best_score\n",
    "        \n",
    "\n",
    "    # Run fuzzy and country matching function\n",
    "    m = merged_df.apply(lambda row: find_best_match(row, df_2), axis=1)\n",
    "\n",
    "    # Unzip best_match and match_score from m and add them as columns to merged_df\n",
    "    merged_df['best_match'], merged_df['match_score'] = zip(*m)\n",
    "\n",
    "    # Merge df_1 with df_2 based on the best_match\n",
    "    merged_df = pd.merge(merged_df, df_2, left_on='best_match', right_on=name_col2, how='left')\n",
    "\n",
    "    # Drop columns that are no longer needed and rename country column\n",
    "    merged_df = merged_df.drop(['competitor', 'country_y', 'best_match', 'match_score'], axis=1)\n",
    "    merged_df = merged_df.rename(columns = {'country_x':'country'})\n",
    "\n",
    "    # Reorder the columns to  visually make more sense\n",
    "    merged_df = merged_df.reindex(columns = ['sport',\n",
    "                                             'season',\n",
    "                                             'competition_name',\n",
    "                                             'event_i_d',\n",
    "                                             'event_name_short',\n",
    "                                             'event_gender',\n",
    "                                             'competition_date',\n",
    "                                             'name',\n",
    "                                             'person_i_d',\n",
    "                                             'person_age_days',\n",
    "                                             'country',\n",
    "                                             'rank',\n",
    "                                             'snatch1',\n",
    "                                             'snatch1_success',\n",
    "                                             'snatch2',\n",
    "                                             'snatch2_success',\n",
    "                                             'snatch3',\n",
    "                                             'snatch3_success',\n",
    "                                             'cj1',\n",
    "                                             'cj1_success',\n",
    "                                             'cj2',\n",
    "                                             'cj2_success',\n",
    "                                             'cj3',\n",
    "                                             'cj3_success',\n",
    "                                             'total'])\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cef0a27-909f-4273-a075-e76028dc8a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the above code to merge dataframes based on fuzzy matches names along with countries\n",
    "final_df = fuzzy_name_merge(weightlift_df, iwf_df, 'competitor', 'name', 'country', 'country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796687e-2b6f-4a84-b30f-d84d780f1e94",
   "metadata": {},
   "source": [
    "## Verify Merge and Write To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334c2022-5a29-4bc2-ae28-2f3e3ec0c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f8b30-950b-488e-9160-65ca11fac150",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write merged data back into Excel file\n",
    "final_df.to_csv('../data/final_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
